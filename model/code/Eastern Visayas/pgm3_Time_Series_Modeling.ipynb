{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT LIBRARIES\n",
    "\n",
    "import itertools\n",
    "import time\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#--- Import Statsmodels\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#--- Import Sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#--- Importing tqdm for the progress bar\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ PICKLE OF THE ORIGINAL AND DIFFERENCED SERIES\n",
    "Dengue_EastVis = pd.read_pickle('C:/Users/Claire/Documents/GitHub/nasa_hack/model/datasets/Dengue_EastVis_Clean.pickle')\n",
    "Dengue_EastVis_diff = pd.read_pickle('C:/Users/Claire/Documents/GitHub/nasa_hack/model/datasets/Dengue_EastVis_Diff.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MTD_Deaths', 'GTrend_Dengue', 'GTrend_Dengue_Fever',\n",
       "       'GTrend_Dengue_Sym', 'Mort_Rate', 'MTD_Cases', 'Reg_Ave_Temp_EastVis',\n",
       "       'Reg_Ave_Rainfall_EastVis'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dengue_EastVis_diff.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE LAGGED VERSIONS OF THE PREDICTORS (MAX OF A QUARTER)\n",
    "Dengue_EastVis_diff['Temp_L1'] = Dengue_EastVis_diff['Reg_Ave_Temp_EastVis'].shift(1)\n",
    "Dengue_EastVis_diff['Temp_L2'] = Dengue_EastVis_diff['Reg_Ave_Temp_EastVis'].shift(2)\n",
    "Dengue_EastVis_diff['Temp_L3'] = Dengue_EastVis_diff['Reg_Ave_Temp_EastVis'].shift(3)\n",
    "\n",
    "Dengue_EastVis_diff['Rain_L1'] = Dengue_EastVis_diff['Reg_Ave_Rainfall_EastVis'].shift(1)\n",
    "Dengue_EastVis_diff['Rain_L2'] = Dengue_EastVis_diff['Reg_Ave_Rainfall_EastVis'].shift(2)\n",
    "Dengue_EastVis_diff['Rain_L3'] = Dengue_EastVis_diff['Reg_Ave_Rainfall_EastVis'].shift(3)\n",
    "\n",
    "Dengue_EastVis_diff['GT_Dengue_L1'] = Dengue_EastVis_diff['GTrend_Dengue'].shift(1)\n",
    "Dengue_EastVis_diff['GT_Dengue_L2'] = Dengue_EastVis_diff['GTrend_Dengue'].shift(2)\n",
    "Dengue_EastVis_diff['GT_Dengue_L3'] = Dengue_EastVis_diff['GTrend_Dengue'].shift(3)\n",
    "\n",
    "Dengue_EastVis_diff['GT_DengueFvr_L1'] = Dengue_EastVis_diff['GTrend_Dengue_Fever'].shift(1)\n",
    "Dengue_EastVis_diff['GT_DengueFvr_L2'] = Dengue_EastVis_diff['GTrend_Dengue_Fever'].shift(2)\n",
    "Dengue_EastVis_diff['GT_DengueFvr_L3'] = Dengue_EastVis_diff['GTrend_Dengue_Fever'].shift(3)\n",
    "\n",
    "Dengue_EastVis_diff['GT_DengueSym_L1'] = Dengue_EastVis_diff['GTrend_Dengue_Sym'].shift(1)\n",
    "Dengue_EastVis_diff['GT_DengueSym_L2'] = Dengue_EastVis_diff['GTrend_Dengue_Sym'].shift(2)\n",
    "Dengue_EastVis_diff['GT_DengueSym_L3'] = Dengue_EastVis_diff['GTrend_Dengue_Sym'].shift(3)\n",
    "\n",
    "#Dengue_EastVis_diff['Cases_L1'] = Dengue_EastVis_diff['MTD_Cases'].shift(1)\n",
    "#Dengue_EastVis_diff['Cases_L2'] = Dengue_EastVis_diff['MTD_Cases'].shift(2)\n",
    "#Dengue_EastVis_diff['Cases_L3'] = Dengue_EastVis_diff['MTD_Cases'].shift(3)\n",
    "\n",
    "Dummies = pd.get_dummies(Dengue_EastVis_diff.index.month, prefix='m')\n",
    "Dengue_EastVis_diff = Dengue_EastVis_diff.reset_index()\n",
    "Dengue_EastVis_diff = Dengue_EastVis_diff.merge(Dummies, left_index=True, right_index=True)\n",
    "Dengue_EastVis_diff.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 35)\n",
      "(12, 35)\n"
     ]
    }
   ],
   "source": [
    "# SPLIT SERIES TO TRAINING AND TEST SETS\n",
    "#--- Set 2018 as the test dataframe\n",
    "nobs = 12\n",
    "df_train, df_test = Dengue_EastVis_diff[0:-nobs], Dengue_EastVis_diff[-nobs:]\n",
    "df_train = df_train.dropna()\n",
    "df_test = df_test.dropna()\n",
    "\n",
    "# Check size\n",
    "print(df_train.shape)  \n",
    "print(df_test.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Temp_L2',\n",
       " 'GT_Dengue_L1',\n",
       " 'GT_Dengue_L3',\n",
       " 'm_2',\n",
       " 'm_3',\n",
       " 'm_4',\n",
       " 'm_5',\n",
       " 'm_6',\n",
       " 'm_7',\n",
       " 'm_8',\n",
       " 'm_9',\n",
       " 'm_10',\n",
       " 'm_11',\n",
       " 'm_12']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PERFORM UNIVARIATE REGRESSION TO TRIM DOWN THE PREDICTORS\n",
    "predictor_col = df_train.columns[df_train.columns.str.contains(pat = '_L')]\n",
    "pvals = pd.DataFrame()\n",
    "for col in predictor_col:\n",
    "    Y = df_train.MTD_Cases\n",
    "    X = df_train[col]\n",
    "    X2 = sm.add_constant(X)\n",
    "    mod = sm.OLS(Y,X)\n",
    "    fit = mod.fit()\n",
    "    pval = fit.summary2().tables[1]['P>|t|']\n",
    "    pval = pval.to_frame()\n",
    "    pvals = pvals.append(pval)\n",
    "\n",
    "# RETAIN ONLY THE LAGGED PREDICTORS WITH SIGNIFICANT P-VALUES\n",
    "pvals = pvals[pvals['P>|t|'] <= 0.05].reset_index()\n",
    "pvals = pvals.rename(columns={'index':'Variable'})\n",
    "shortlist_predictor_col = pvals['Variable']\n",
    "dummy = pd.Series(df_train.columns[df_train.columns.str.startswith('m_')])\n",
    "shortlist_predictor_col = shortlist_predictor_col.append(dummy)\n",
    "X = df_train[shortlist_predictor_col].drop(columns=['m_1'],axis=1)\n",
    "#X = df_train[shortlist_predictor_col]\n",
    "list(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_linear_reg(X,Y):\n",
    "    #Fit linear regression model \n",
    "    X2 = sm.add_constant(X)\n",
    "    model_k = sm.OLS(Y,X2)\n",
    "    fit = model_k.fit()\n",
    "    pvalues = fit.pvalues\n",
    "    worst_pval = pvalues.max() \n",
    "    worst_feature = pvalues.argmax()\n",
    "    Y_Pred_Test = fit.predict(sm.add_constant(df_test[list(X)]))\n",
    "    \n",
    "    if worst_feature == 'const':\n",
    "        model_k = sm.OLS(Y,X)\n",
    "        fit = model_k.fit()\n",
    "        pvalues = fit.pvalues\n",
    "        worst_pval = pvalues.max() \n",
    "        worst_feature = pvalues.argmax()\n",
    "        Y_Pred_Test = fit.predict(df_test[list(X)])\n",
    "        \n",
    "    pval = fit.pvalues.to_frame()\n",
    "    features = list(pval.index)\n",
    "    pvals = list(pval[0])\n",
    "    sig = pval[pval[0]<=0.05]\n",
    "    pct_sig = len(list(sig[0])) / len(list(pval[0]))\n",
    "    rsq = fit.rsquared\n",
    "    adjr = fit.rsquared_adj\n",
    "    serial_corr = list(sm.stats.diagnostic.acorr_breusch_godfrey(fit, nlags=3))[3]\n",
    "    het_arch = list(sm.stats.diagnostic.het_arch(fit.resid, maxlag=1))[3]\n",
    "    normality = list(sm.stats.stattools.jarque_bera(fit.resid))[1]\n",
    "    \n",
    "    mae = mean_absolute_error(Y_True_Test,Y_Pred_Test)\n",
    "    mse = mean_squared_error(Y_True_Test,Y_Pred_Test)\n",
    "    rmse = sqrt(mean_squared_error(Y_True_Test,Y_Pred_Test))\n",
    "    return features, pvals, pct_sig, rsq, adjr, serial_corr, het_arch, normality, mae, mse, rmse, worst_pval, worst_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\Claire\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  \n",
      "E:\\Users\\Claire\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# INITIALIZE VARIABLES\n",
    "#X = df_train[df_train.columns[df_train.columns.str.contains(r'_L|m_')]]\n",
    "Y = df_train.MTD_Cases\n",
    "Y_True_Test = df_test.MTD_Cases\n",
    "threshold_out = 0.05\n",
    "\n",
    "remaining_features = list(X.columns.values)\n",
    "features = []\n",
    "R_squared_list, AdjR2_list, feature_list, pval_list = [],[],[],[]\n",
    "pct_sig_list = []\n",
    "num_features = []\n",
    "serial_corr_list = []\n",
    "het_arch_list = []\n",
    "norm_list = []\n",
    "mae_list, mse_list, rmse_list = [],[],[]\n",
    "\n",
    "# RUN BACKWARD STEPWISE REGRESSION \n",
    "#--- Remove predictors one at a time until there is no more p-value exceeding the threshold\n",
    "while True:\n",
    "    changed = False\n",
    "    tmp_result = fit_linear_reg(X[list(set(remaining_features))],Y)  \n",
    "    num_features.append(len(remaining_features)) \n",
    "    feature_list.append(tmp_result[0])\n",
    "    pval_list.append(tmp_result[1])\n",
    "    pct_sig_list.append(tmp_result[2])\n",
    "    R_squared_list.append(tmp_result[3])\n",
    "    AdjR2_list.append(tmp_result[4])\n",
    "    serial_corr_list.append(tmp_result[5])\n",
    "    het_arch_list.append(tmp_result[6])\n",
    "    norm_list.append(tmp_result[7])\n",
    "    mae_list.append(tmp_result[8])\n",
    "    mse_list.append(tmp_result[9])\n",
    "    rmse_list.append(tmp_result[10])\n",
    "    \n",
    "    if tmp_result[11] > threshold_out:\n",
    "        changed = True\n",
    "        remaining_features.remove(tmp_result[12])\n",
    "        \n",
    "    if not changed:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STORE IN DATAFRAME\n",
    "subsets_df = pd.DataFrame({'num_features': num_features, 'features': feature_list, 'P>|t|': pval_list, 'pct_sig': pct_sig_list, \\\n",
    "                          'rsq': R_squared_list, 'adj_rsq': AdjR2_list, 'serial_corr': serial_corr_list, 'het': het_arch_list, \\\n",
    "                          'normality': norm_list, 'mae': mae_list, 'mse': mse_list, 'rmse': rmse_list})\n",
    "\n",
    "# RETAIN ONLY THE SUBSET MODELS WHICH PASSED THE DIAGNOSTIC TESTS\n",
    "subsets_df = subsets_df[(subsets_df['serial_corr'] > 0.05) & (subsets_df['het'] > 0.05) & (subsets_df['normality'] > 0.05)]\n",
    "\n",
    "# GET ONLY THE TOP 3 MODELS BY ADJUSTED R-SQUARED\n",
    "top3_subsets_df = subsets_df.nlargest(3,'adj_rsq').reset_index().drop(columns=['index'])\n",
    "top3_subsets_df.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RERUN THE TOP 3 MODELS AND STORE THE FORECASTS FOR BOTH TRAINING AND TEST SETS\n",
    "Y = df_train['MTD_Cases']\n",
    "\n",
    "for i in range(1,4):\n",
    "    top = top3_subsets_df['features'][i]\n",
    "    if top.count('const') == 0:\n",
    "        X = df_train[top]    \n",
    "        reg = LinearRegression(fit_intercept=False)\n",
    "\n",
    "    if top.count('const') > 0:\n",
    "        top.remove('const')\n",
    "        X = df_train[top]    \n",
    "        reg = LinearRegression(fit_intercept=True)\n",
    "\n",
    "    reg.fit(X,Y)\n",
    "    prediction = pd.DataFrame(reg.predict(X))\n",
    "    prediction.columns = ['Pred_Model_'] \n",
    "    prediction.columns += str(i)\n",
    "    if i == 1:\n",
    "        df_train2 = df_train.reset_index().join(prediction, how='inner')\n",
    "    if i > 1:\n",
    "        df_train2 = df_train2.reset_index().join(prediction, how='inner')\n",
    "\n",
    "    prediction = pd.DataFrame(reg.predict(df_test[X.columns]))\n",
    "    prediction.columns = ['Pred_Model_']\n",
    "    prediction.columns += str(i)\n",
    "    if i == 1:\n",
    "        df_test2 = df_test.reset_index().join(prediction, how='inner')\n",
    "    if i > 1:\n",
    "        df_test2 = df_test2.reset_index().join(prediction, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REVERT THE FORECAST TO THE ORIGINAL FORM FROM PERCENTAGE CHANGE\n",
    "Dengue_EastVis_Fct = df_train2.append(df_test2, ignore_index=True)\n",
    "Dengue_EastVis_Fct = Dengue_EastVis_Fct[['Date','Pred_Model_1','Pred_Model_2','Pred_Model_3']]\n",
    "Dengue_EastVis_Fct['Pred_Model_1'] += 1\n",
    "Dengue_EastVis_Fct['Pred_Model_2'] += 1\n",
    "Dengue_EastVis_Fct['Pred_Model_3'] += 1\n",
    "Dengue_EastVis_Fct = Dengue_EastVis_Fct.rename(columns={'Pred_Model_1': 'Pred_PctChg_1', 'Pred_Model_2': 'Pred_PctChg_2', \\\n",
    "                'Pred_Model_3': 'Pred_PctChg_3'})\n",
    "Dengue_EastVis_Fct.set_index('Date', inplace=True)\n",
    "\n",
    "Dengue_EastVis2 = Dengue_EastVis.merge(Dengue_EastVis_Fct,how='left',on='Date')\n",
    "Dengue_EastVis2['MTD_Cases_Fct_1'] = Dengue_EastVis2.MTD_Cases.shift(1) * Dengue_EastVis2['Pred_PctChg_1']\n",
    "Dengue_EastVis2['MTD_Cases_Fct_2'] = Dengue_EastVis2.MTD_Cases.shift(1) * Dengue_EastVis2['Pred_PctChg_2']\n",
    "Dengue_EastVis2['MTD_Cases_Fct_3'] = Dengue_EastVis2.MTD_Cases.shift(1) * Dengue_EastVis2['Pred_PctChg_3']\n",
    "Dengue_EastVis2 = Dengue_EastVis2.drop(columns=['Pred_PctChg_1','Pred_PctChg_2','Pred_PctChg_3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE MODEL DATAFRAMES TO PICKLE\n",
    "top3_subsets_df.to_pickle('C:/Users/Claire/Documents/GitHub/nasa_hack/model/datasets/Dengue_EastVis_Top3_Models.pickle')\n",
    "Dengue_EastVis2.to_pickle('C:/Users/Claire/Documents/GitHub/nasa_hack/model/datasets/Dengue_EastVis_Fct.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT PICKLES TO EXCEL \n",
    "writer = pd.ExcelWriter('C:/Users/Claire/Documents/GitHub/nasa_hack/model/datasets/Dengue_EastVis_Fct.xlsx', engine='xlsxwriter')\n",
    "Dengue_EastVis2.to_excel(writer, sheet_name='Fct')\n",
    "top3_subsets_df.to_excel(writer, sheet_name='Model')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
